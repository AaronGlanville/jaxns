{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Auto-Regressive Model (GPAR)\n",
    "\n",
    "The GPAR model is formed by assuming a \"closed downward\" dependence structure for the data, i.e. if $(x, y_i) \\in D$ that $(x, y_j) \\in D$ for all $j \\le i$. We then write the joint as a factored model,\n",
    "\n",
    "$$\n",
    "p(y_1, \\ldots, y_n) = p(y_1) p(y_2 | y_1) \\ldots p(y_n | y_{n-1}, y_{n-2}, \\ldots, y_1)\n",
    "$$\n",
    "where each $y_i$ is assumed to be a Gaussian process, and given noise variances $\\sigma_i^2$. The input to each GP is are the coordinates and the posterior mean of all preceding dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T17:51:57.970454710Z",
     "start_time": "2023-10-02T17:51:55.652551117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO[2023-10-02 19:51:57,596]: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO[2023-10-02 19:51:57,598]: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO[2023-10-02 19:51:57,603]: Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "WARNING[2023-10-02 19:51:57,604]: No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# For Gaussian processes 64bit is important\n",
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "from functools import cached_property\n",
    "from typing import Tuple, Dict, NamedTuple\n",
    "\n",
    "from jax import tree_map\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "from jax.scipy.linalg import solve_triangular\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "from jaxns.types import float_type\n",
    "from jaxns import Prior, Model\n",
    "from jaxns.utils import marginalise_static_from_U, evaluate_map_estimate_from_U\n",
    "\n",
    "tfpd = tfp.distributions\n",
    "tfpk = tfp.math.psd_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T17:51:59.351949094Z",
     "start_time": "2023-10-02T17:51:57.985816741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create toy data set.\n",
    "n = 100\n",
    "x = jnp.linspace(0.2, 1.2, n)\n",
    "noise = 0.1\n",
    "\n",
    "# Draw functions depending on each other in complicated ways.\n",
    "f1 = -jnp.sin(10 * jnp.pi * (x + 1)) / (2 * x + 1) - x ** 4\n",
    "f2 = jnp.cos(f1) ** 2 + jnp.sin(3 * x)\n",
    "f3 = f2 * f1 ** 2 + 3 * x\n",
    "f = jnp.stack((f1, f2, f3), axis=1)\n",
    "\n",
    "# Add noise and subsample.\n",
    "y = f + noise * random.normal(random.PRNGKey(42), shape=(n, 3))\n",
    "x_obs, y_obs = x[:n // 2:6], y[:n // 2:6]\n",
    "y_obs_var = jnp.ones(y_obs.shape) * noise ** 2\n",
    "\n",
    "for i in range(3):\n",
    "    plt.plot(x, f[:, i], label='f{}'.format(i))\n",
    "    plt.scatter(x_obs, y_obs[:, i], label='y{}'.format(i))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T17:51:59.417062218Z",
     "start_time": "2023-10-02T17:51:59.370263511Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def log_normal_with_mask(x, mean, cov, sigma):\n",
    "    \"\"\"\n",
    "    Computes log-Normal density in a numerically stable way so that sigma can contain +inf for masked data.\n",
    "\n",
    "    Args:\n",
    "        x: RV value\n",
    "        mean: mean of Gaussian\n",
    "        cov: covariance of underlying, minus the obs. covariance\n",
    "        sigma: stddev's of obs. error, inf encodes an outlier.\n",
    "\n",
    "    Returns: a normal density for all points not of inf stddev obs. error.\n",
    "    \"\"\"\n",
    "    C = cov / (sigma[:, None] * sigma[None, :]) + jnp.eye(cov.shape[0])\n",
    "    L = jnp.linalg.cholesky(C)\n",
    "    Ls = sigma[:, None] * L\n",
    "    log_det = jnp.sum(jnp.where(jnp.isinf(sigma), 0., jnp.log(jnp.diag(Ls))))\n",
    "    dx = (x - mean)\n",
    "    dx = solve_triangular(L, dx / sigma, lower=True)\n",
    "    maha = dx @ dx\n",
    "    log_likelihood = -0.5 * jnp.sum(~jnp.isinf(sigma)) * jnp.log(2. * jnp.pi) \\\n",
    "                     - log_det \\\n",
    "                     - 0.5 * maha\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "class GaussianProcessData(NamedTuple):\n",
    "    X: List[jnp.ndarray]\n",
    "    Y: jnp.ndarray\n",
    "    Y_var: jnp.ndarray\n",
    "    sample_size: jnp.ndarray\n",
    "\n",
    "\n",
    "def _assert_rank(rank: int, **kwargs):\n",
    "    for name, t in kwargs.items():\n",
    "        if len(t.shape) != rank:\n",
    "            raise ValueError(f\"{name} shoue be rank {rank} got {t.shape}.\")\n",
    "\n",
    "\n",
    "def _assert_same_leading_dim(*args):\n",
    "    n = set()\n",
    "    for arg in args:\n",
    "        n.add(arg.shape[0])\n",
    "    if len(n) > 1:\n",
    "        raise ValueError(f\"Got mismatched leading dimensions: {n}\")\n",
    "\n",
    "\n",
    "def _ensure_gaussian_process_data(data: GaussianProcessData) -> GaussianProcessData:\n",
    "    data = tree_map(lambda x: jnp.asarray(x, float_type), data)\n",
    "    _assert_rank(2, U=data.X)\n",
    "    _assert_rank(1, sample_size=data.sample_size, Y=data.Y, Y_var=data.Y_var)\n",
    "    _assert_same_leading_dim(*data)\n",
    "    if data.Y.shape[0] < 2:\n",
    "        raise ValueError('Need more samples to form mean and variance of data.')\n",
    "    return data\n",
    "\n",
    "\n",
    "def eval_kernels(kernels: List[tfp.math.psd_kernels.PositiveSemidefiniteKernel | None], X1: List[jnp.ndarray],\n",
    "                 X2: List[jnp.ndarray]):\n",
    "    \"\"\"\n",
    "    Evaluates the kernel function between the coordinates X1 and X2.\n",
    "    \n",
    "    Args:\n",
    "        kernels: The kernel functions.\n",
    "        X1: The first set of coordinates.\n",
    "        X2: The second set of coordinates.\n",
    "\n",
    "    Returns:\n",
    "        The kernel matrix.\n",
    "    \"\"\"\n",
    "    kernels = list(filter(lambda x: x is not None, kernels))\n",
    "    assert len(kernels) == len(X1) == len(X2), f\"Got {len(kernels)} kernels, {len(X1)} X1, {len(X2)} X2. {kernels}\"\n",
    "    Ks = [kernel.matrix(x1, x2) for kernel, x1, x2 in zip(kernels, X1, X2)]\n",
    "    return sum(Ks[1:], Ks[0])\n",
    "\n",
    "\n",
    "def marginal_likelihood_with_mask(kernels: List[tfp.math.psd_kernels.PositiveSemidefiniteKernel],\n",
    "                                  data: GaussianProcessData,\n",
    "                                  variance: jnp.ndarray,\n",
    "                                  mean: jnp.ndarray) -> jnp.ndarray:\n",
    "    Kxx = eval_kernels(kernels, data.X, data.X)\n",
    "    no_uncert_data = jnp.isnan(data.Y_var)\n",
    "\n",
    "    variance = jnp.where(no_uncert_data,\n",
    "                         variance,\n",
    "                         data.Y_var)\n",
    "\n",
    "    sigma = jnp.sqrt(jnp.maximum(1e-6, variance))\n",
    "    return log_normal_with_mask(x=data.Y, mean=mean, cov=Kxx, sigma=sigma)\n",
    "\n",
    "\n",
    "def posterior_with_mask(Xstar: List[jnp.ndarray],\n",
    "                        kernels: List[tfp.math.psd_kernels.PositiveSemidefiniteKernel],\n",
    "                        data: GaussianProcessData,\n",
    "                        variance: jnp.ndarray,\n",
    "                        mean: jnp.ndarray,\n",
    "                        cov: bool = False) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the posterior mean and variance of a Gaussian process, given the data, and a mask.\n",
    "\n",
    "    Args:\n",
    "        Xstar: List of input coordinates [H, D_i]\n",
    "        kernels: The kernel functions.\n",
    "        data: The data, where masked data has inf variance.\n",
    "        variance: The variance of the posterior mean.\n",
    "        mean: The posterior mean.\n",
    "        cov: If True, return the full covariance matrix, otherwise return the diagonal.\n",
    "\n",
    "    Returns:\n",
    "        The posterior mean, and variance of the data\n",
    "    \"\"\"\n",
    "\n",
    "    Kxx = eval_kernels(kernels, data.X, data.X)\n",
    "    Kxs = eval_kernels(kernels, data.X, Xstar)\n",
    "    Kss = eval_kernels(kernels, Xstar, Xstar)\n",
    "\n",
    "    variance = data.Y_var\n",
    "    std_dev = jnp.sqrt(jnp.maximum(1e-6, variance))\n",
    "\n",
    "    L = jnp.linalg.cholesky(Kxx / (std_dev[:, None] * std_dev[None, :]) + jnp.eye(std_dev.size))\n",
    "    # L = jnp.where(jnp.isnan(L), jnp.eye(L.shape[0])/sigma, L)\n",
    "\n",
    "    J = solve_triangular(L, Kxs / std_dev[:, None],\n",
    "                         lower=True)  # same J as below, but safely taking into account inf mask.\n",
    "\n",
    "    post_cov_s = Kss - J.T @ J\n",
    "\n",
    "    dY = data.Y - mean\n",
    "    dX = solve_triangular(L, dY / std_dev, lower=True)\n",
    "    post_mu_s = mean + J.T @ dX  # mu + J^T L^-1 dY = mu - J^T dX\n",
    "\n",
    "    if cov:\n",
    "        return post_mu_s, post_cov_s\n",
    "    return post_mu_s, jnp.diag(post_cov_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T17:51:59.448090251Z",
     "start_time": "2023-10-02T17:51:59.373745131Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from jaxns.abc import PriorModelGen\n",
    "from jaxns.evidence_maximisation import ParametrisedModel, EM, prior_to_parametrised_singular\n",
    "from jaxns import NestedSamplerResults, summary, plot_diagnostics, plot_cornerplot\n",
    "from jaxns.prior import PriorModelType\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Normaliser:\n",
    "    \"\"\"\n",
    "    Normalises data to zero mean and unit variance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X: jnp.ndarray, Y: jnp.ndarray, Y_var: jnp.ndarray):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Y_var = Y_var\n",
    "\n",
    "    @property\n",
    "    def normalisation_params(self) -> Dict[str, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Computes the normalisation parameters for the data.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the normalisation parameters.\n",
    "        \"\"\"\n",
    "        X_loc = jnp.nanmean(self.X, axis=0, keepdims=True)\n",
    "        X_scale = jnp.nanstd(self.X, axis=0, keepdims=True)\n",
    "        Y_loc = jnp.nanmean(self.Y, axis=0, keepdims=True)\n",
    "        Y_scale = jnp.nanstd(self.Y, axis=0, keepdims=True)\n",
    "        return dict(\n",
    "            X_loc=X_loc,\n",
    "            X_scale=X_scale,\n",
    "            Y_loc=Y_loc,\n",
    "            Y_scale=Y_scale\n",
    "        )\n",
    "\n",
    "    def normalise_X(self, X: jnp.ndarray):\n",
    "        return (X - self.normalisation_params['X_loc']) / self.normalisation_params['X_scale']\n",
    "\n",
    "    def normalise_Y(self, Y: jnp.ndarray):\n",
    "        return (Y - self.normalisation_params['Y_loc']) / self.normalisation_params['Y_scale']\n",
    "\n",
    "    def normalise_Y_var(self, Y_var: jnp.ndarray):\n",
    "        return Y_var / jnp.square(self.normalisation_params['Y_scale'])\n",
    "\n",
    "    def normalise_data(self, X: jnp.ndarray, Y: jnp.ndarray, Y_var: jnp.ndarray):\n",
    "        return self.normalise_X(X), self.normalise_Y(Y), self.normalise_Y_var(Y_var)\n",
    "\n",
    "    def unnormalise_X(self, X: jnp.ndarray):\n",
    "        return X * self.normalisation_params['X_scale'] + self.normalisation_params['X_loc']\n",
    "\n",
    "    def unnormalise_Y(self, Y: jnp.ndarray):\n",
    "        return Y * self.normalisation_params['Y_scale'] + self.normalisation_params['Y_loc']\n",
    "\n",
    "    def unnormalise_Y_var(self, Y_var: jnp.ndarray):\n",
    "        return Y_var * jnp.square(self.normalisation_params['Y_scale'])\n",
    "\n",
    "    def unnormlise_data(self, X: jnp.ndarray, Y: jnp.ndarray, Y_var: jnp.ndarray):\n",
    "        return self.unnormalise_X(X), self.unnormalise_Y(Y), self.unnormalise_Y_var(Y_var)\n",
    "\n",
    "\n",
    "class GPAR:\n",
    "    def __init__(self, X: jnp.ndarray, Y: jnp.ndarray, Y_var: jnp.ndarray, markov_ndims: int = None,\n",
    "                 replace: bool = False, impute: bool = False):\n",
    "        \"\"\"\n",
    "        Gaussian Process Auto-Regressive Model (GPAR) for M-dimensional data.\n",
    "\n",
    "        Args:\n",
    "            X: The input coordinates [N, D]\n",
    "            Y: The data values [N, M]\n",
    "            Y_var: The variance of the data values [N, M]\n",
    "            markov_ndims: The number of dimensions to condition on. If None, all preceding dimensions are conditioned on.\n",
    "            replace: If True, replace the data with the posterior mean of the previous conditional.\n",
    "            impute: If True, impute missing data using the posterior mean of the previous conditional. \n",
    "                Missing data have Y_var[i, j] == inf or Y[i, j] == nan.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Y_var = Y_var\n",
    "        self.markov_ndims = markov_ndims\n",
    "        self.normaliser = Normaliser(X, Y, Y_var)\n",
    "        self.replace = replace\n",
    "        self.impute = impute\n",
    "\n",
    "    def model(self) -> ParametrisedModel:\n",
    "        return ParametrisedModel(\n",
    "            base_model=Model(prior_model=self._build_prior_model(), log_likelihood=self._log_likelihood)\n",
    "        )\n",
    "\n",
    "    def get_markov_dims_iterator(self):\n",
    "        \"\"\"\n",
    "        Returns an iterator over the output dimensions which condition a given output dimension.\n",
    "        \n",
    "        Returns:\n",
    "            An iterator that produces (i, [j, k, ...]) where i is the output dimension, and j, k, ... are the conditioning dimensions.\n",
    "        \"\"\"\n",
    "        for i in range(self.ndims):\n",
    "            last_dim = max(0, i - 1)\n",
    "            first_dim = max(0, last_dim - self.markov_ndims) if self.markov_ndims is not None else 0\n",
    "            conditional_dims = list(range(first_dim, last_dim + 1))\n",
    "            yield i, conditional_dims\n",
    "\n",
    "    def _build_prior_model(self) -> PriorModelType:\n",
    "        # Assumes input data is normalised.\n",
    "\n",
    "        def prior_model() -> PriorModelGen:\n",
    "            uncerts = []\n",
    "            kernel_params = []\n",
    "            input_kernel_params = []\n",
    "\n",
    "            D = self.X.shape[1]\n",
    "\n",
    "            for (i, markov_dims) in self.get_markov_dims_iterator():\n",
    "\n",
    "                # Non-linear\n",
    "\n",
    "                input_length_scale = yield prior_to_parametrised_singular(Prior(tfpd.HalfNormal(0.1 * jnp.ones((D,))),\n",
    "                                                                                name=f'X_length_scale_{i}'))  # [D]\n",
    "                input_amplitude = yield prior_to_parametrised_singular(Prior(tfpd.HalfNormal(1.),\n",
    "                                                                             name=f'X_amplitude_{i}'))  # [1]\n",
    "\n",
    "                # Linear\n",
    "\n",
    "                bias_amplitude = yield prior_to_parametrised_singular(\n",
    "                    Prior(tfpd.HalfNormal(10.), name=f'X_bias_amplitude_{i}'))  # [1]\n",
    "                slope_amplitude = yield prior_to_parametrised_singular(\n",
    "                    Prior(tfpd.HalfNormal(10.), name=f'X_slope_amplitude_{i}'))  # [1]\n",
    "                input_linear_param = dict(bias_amplitude=bias_amplitude, slope_amplitude=slope_amplitude)\n",
    "\n",
    "                # Periodic\n",
    "                input_periodic_amplitude = yield prior_to_parametrised_singular(\n",
    "                    Prior(tfpd.HalfNormal(1.), name=f'X_periodic_amplitude_{i}'))  # [1]\n",
    "                input_periodic_length_scale = yield prior_to_parametrised_singular(\n",
    "                    Prior(tfpd.HalfNormal(1.), name=f'X_periodic_length_scale_{i}'))  # [1]\n",
    "                input_periodic_period = yield prior_to_parametrised_singular(\n",
    "                    Prior(tfpd.HalfNormal(1.), name=f'X_periodic_period_{i}'))  # [1]\n",
    "\n",
    "                input_kernel_param = dict(\n",
    "                    linear=input_linear_param,\n",
    "                    non_linear=dict(length_scale=input_length_scale, amplitude=input_amplitude),\n",
    "                    periodic=dict(length_scale=input_periodic_length_scale, amplitude=input_periodic_amplitude,\n",
    "                                  period=input_periodic_period)\n",
    "                )\n",
    "                input_kernel_params.append(input_kernel_param)\n",
    "\n",
    "                uncert = yield Prior(tfpd.HalfNormal(0.2), name='uncert_{}'.format(i))  # [1]\n",
    "                uncerts.append(uncert)\n",
    "\n",
    "                num_preceding_dims = len(markov_dims)\n",
    "                if i == 0:\n",
    "                    kernel_params.append(None)\n",
    "                    continue\n",
    "\n",
    "                length_scale = yield Prior(tfpd.HalfNormal(5 * jnp.ones((num_preceding_dims,))),\n",
    "                                           name='length_scale_{}'.format(i))  # [num_preceding_dims]\n",
    "                amplitude = yield Prior(tfpd.HalfNormal(5.),\n",
    "                                        name='amplitude_{}'.format(i))  # [num_preceding_dims]\n",
    "                nonlinear_param = dict(length_scale=length_scale, amplitude=amplitude)\n",
    "\n",
    "                bias_amplitude = yield Prior(tfpd.HalfNormal(10.), name='bias_amplitude_{}'.format(i))  # [1]\n",
    "                slope_amplitude = yield Prior(tfpd.HalfNormal(10.), name='slope_amplitude_{}'.format(i))  # [1]\n",
    "                linear_param = dict(bias_amplitude=bias_amplitude, slope_amplitude=slope_amplitude)\n",
    "\n",
    "                kernel_params.append(dict(non_linear=nonlinear_param, linear=linear_param))\n",
    "\n",
    "            return uncerts, input_kernel_params, kernel_params\n",
    "\n",
    "        return prior_model\n",
    "\n",
    "    def _build_kernel(self, input_kernel_param: Dict[str, Dict[str, jnp.ndarray]],\n",
    "                      output_kernel_param: Dict[str, Dict[str, jnp.ndarray]] | None) -> Tuple[\n",
    "        tfpk.PositiveSemidefiniteKernel, tfpk.PositiveSemidefiniteKernel | None]:\n",
    "        \"\"\"\n",
    "        Builds the input and output kernels.\n",
    "        \n",
    "        Args:\n",
    "            input_kernel_param: The parameters of the input kernel.\n",
    "            output_kernel_param: The parameters of the output kernel.\n",
    "\n",
    "        Returns:\n",
    "            The input and output kernels.\n",
    "        \"\"\"\n",
    "        output_kernel_param = output_kernel_param.copy() if output_kernel_param is not None else None\n",
    "\n",
    "        # Linear component\n",
    "\n",
    "        input_linear = tfpk.Linear(**input_kernel_param['linear'])\n",
    "\n",
    "        # Nonlinear component\n",
    "\n",
    "        input_length_scale = input_kernel_param['non_linear'].pop('length_scale')\n",
    "        base_input_kernel = tfpk.ExponentiatedQuadratic(**input_kernel_param['non_linear'])\n",
    "        input_non_linear_kernel = tfpk.FeatureTransformed(base_input_kernel, lambda x, _, __: x / input_length_scale)\n",
    "\n",
    "        # Periodic component\n",
    "\n",
    "        input_periodic = tfpk.ExpSinSquared(**input_kernel_param['periodic'])\n",
    "\n",
    "        input_kernel = input_linear + input_non_linear_kernel + input_periodic\n",
    "\n",
    "        # Each output kernel has a linear and non-linear component\n",
    "        if output_kernel_param is not None:\n",
    "            # Linear component\n",
    "            output_linear = tfpk.Linear(**output_kernel_param['linear'])\n",
    "\n",
    "            # Nonlinear component\n",
    "            output_length_scale = output_kernel_param['non_linear'].pop('length_scale')\n",
    "            base_output_kernel = tfpk.ExponentiatedQuadratic(**output_kernel_param['non_linear'])\n",
    "            output_non_linear = tfpk.FeatureTransformed(base_output_kernel, lambda x, _, __: x / output_length_scale)\n",
    "\n",
    "            output_kernel = output_linear + output_non_linear\n",
    "        else:\n",
    "            output_kernel = None\n",
    "\n",
    "        return input_kernel, output_kernel\n",
    "\n",
    "    def _log_likelihood(self, uncerts: List[jnp.ndarray],\n",
    "                        input_kernel_params: List[Dict[str, Dict[str, jnp.ndarray]]],\n",
    "                        output_kernel_params: List[Dict[str, Dict[str, jnp.ndarray]] | None]) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the log likelihood of P(y_i | y_{i-1}, y_{i-2}, ..., y_1) using the ordering of input data.\n",
    "\n",
    "        Args:\n",
    "            uncerts: The uncertainty of each dimension.\n",
    "            input_kernel_params: The parameters of the input kernel.\n",
    "            output_kernel_params: The parameters of the output kernel.\n",
    "\n",
    "        Returns:\n",
    "             The log likelihood of the data.\n",
    "        \"\"\"\n",
    "        # We do this by sequentially computing log P(y_i | y_{i-1}, y_{i-2}, ..., y_1) and summing\n",
    "        log_prob = []\n",
    "        X, Y, Y_var = self.X, self.Y, self.Y_var  #self.normaliser.normalise_data(self.X, self.Y, self.Y_var)\n",
    "        output_coords = []\n",
    "        for i, markov_dims in self.get_markov_dims_iterator():\n",
    "            uncert_i = uncerts[i]\n",
    "            input_kernel_param = input_kernel_params[i]\n",
    "            output_kernel_param = output_kernel_params[i]\n",
    "\n",
    "            kernels = self._build_kernel(\n",
    "                input_kernel_param=input_kernel_param,\n",
    "                output_kernel_param=output_kernel_param\n",
    "            )\n",
    "\n",
    "            Y_i = Y[:, i]  # [N, 1]\n",
    "            Y_var_i = Y_var[:, i]  # [N, 1]\n",
    "            Y_var_i = jnp.where(jnp.isnan(Y_var_i), uncert_i ** 2, Y_var_i)\n",
    "\n",
    "            if i == 0:\n",
    "                data = GaussianProcessData(X=[X], Y=Y_i, Y_var=Y_var_i, sample_size=jnp.ones_like(Y_i))\n",
    "                log_prob_i = marginal_likelihood_with_mask(kernels=kernels, data=data, variance=uncert_i ** 2, mean=0.)\n",
    "                if self.replace:\n",
    "                    post_mean_i, post_var_i = posterior_with_mask(Xstar=[X], kernels=kernels, data=data,\n",
    "                                                                  variance=uncert_i ** 2, mean=0.)\n",
    "                    output_coords.append(post_mean_i[:, None])\n",
    "                else:\n",
    "                    output_coords.append(Y_i[:, None])\n",
    "            else:\n",
    "                coords_i = jnp.concatenate(output_coords, axis=1)\n",
    "                data = GaussianProcessData(X=[X, coords_i], Y=Y_i, Y_var=Y_var_i, sample_size=jnp.ones_like(Y_i))\n",
    "                log_prob_i = marginal_likelihood_with_mask(kernels=kernels, data=data, variance=uncert_i ** 2, mean=0.)\n",
    "                if self.replace:\n",
    "                    post_mean_i, post_var_i = posterior_with_mask(Xstar=[X, coords_i], kernels=kernels, data=data,\n",
    "                                                                  variance=uncert_i ** 2, mean=0.)\n",
    "                    output_coords.append(post_mean_i[:, None])\n",
    "                else:\n",
    "                    output_coords.append(Y_i[:, None])\n",
    "            log_prob.append(log_prob_i)\n",
    "\n",
    "        log_prob = sum(log_prob[1:], log_prob[0])\n",
    "        return log_prob\n",
    "\n",
    "    @property\n",
    "    def ndims(self) -> int:\n",
    "        \"\"\"\n",
    "        The number of observable dimensions.\n",
    "        \"\"\"\n",
    "        return self.Y.shape[1]\n",
    "\n",
    "    def predict_f(self, Xstar: jnp.ndarray, uncerts: List[jnp.ndarray],\n",
    "                  input_kernel_params: List[Dict[str, Dict[str, jnp.ndarray]]],\n",
    "                  output_kernel_params: List[Dict[str, Dict[str, jnp.ndarray]] | None]) -> \\\n",
    "            Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Computes the posterior mean of P(f_i | y_{i-1}, y_{i-2}, ..., y_1) using the ordering of input data.\n",
    "\n",
    "        Args:\n",
    "            Xstar: The input coordinates [H, D]\n",
    "            uncerts: The uncertainty of each dimension.\n",
    "            input_kernel_params: The parameters of the input kernel.\n",
    "            output_kernel_params: The parameters of the output kernel.\n",
    "\n",
    "        Returns:\n",
    "             The posterior mean, and variance of the data\n",
    "        \"\"\"\n",
    "        Xstar = jnp.atleast_2d(jnp.asarray(Xstar))\n",
    "        if Xstar.shape[1] != self.X.shape[1]:\n",
    "            raise ValueError(\"Xstar must have the same number of dimensions as X\")\n",
    "\n",
    "        # We do this be sequentially\n",
    "        # 1. computing the posterior mean of each dimension,\n",
    "        # 2. concatenating the coordinates and posterior mean of the preceding dimensions.\n",
    "\n",
    "        X, Y, Y_var = self.X, self.Y, self.Y_var  # self.normaliser.normalise_data(self.X, self.Y, self.Y_var)\n",
    "        # Xstar = self.normaliser.normalise_X(Xstar)\n",
    "        output_coords = []\n",
    "        star_output_coords = []\n",
    "        post_means_star = []\n",
    "        post_vars_star = []\n",
    "\n",
    "        for i, markov_dims in self.get_markov_dims_iterator():\n",
    "            uncert_i = uncerts[i]\n",
    "            input_kernel_param = input_kernel_params[i]\n",
    "            output_kernel_param = output_kernel_params[i]\n",
    "\n",
    "            kernels = self._build_kernel(\n",
    "                input_kernel_param=input_kernel_param,\n",
    "                output_kernel_param=output_kernel_param\n",
    "            )\n",
    "\n",
    "            Y_i = Y[:, i]  # [N, 1]\n",
    "            Y_var_i = Y_var[:, i]  # [N, 1]\n",
    "            Y_var_i = jnp.where(jnp.isnan(Y_var_i), uncert_i ** 2, Y_var_i)\n",
    "\n",
    "            if i == 0:\n",
    "                data = GaussianProcessData(X=[X], Y=Y_i, Y_var=Y_var_i, sample_size=jnp.ones_like(Y_i))\n",
    "                if self.replace:\n",
    "                    post_mean_i, post_var_i = posterior_with_mask(Xstar=[X], kernels=kernels, data=data,\n",
    "                                                                  variance=uncert_i ** 2, mean=0.)\n",
    "                    output_coords.append(post_mean_i[:, None])\n",
    "                else:\n",
    "                    output_coords.append(Y_i[:, None])\n",
    "                star_post_mean_i, star_post_var_i = posterior_with_mask(Xstar=[Xstar], kernels=kernels, data=data,\n",
    "                                                                        variance=uncert_i ** 2, mean=0.)\n",
    "            else:\n",
    "                coords_i = jnp.concatenate(output_coords, axis=1)\n",
    "                star_coords_i = jnp.concatenate(star_output_coords, axis=1)\n",
    "                data = GaussianProcessData(X=[X, coords_i], Y=Y_i, Y_var=Y_var_i, sample_size=jnp.ones_like(Y_i))\n",
    "                if self.replace:\n",
    "                    post_mean_i, post_var_i = posterior_with_mask(Xstar=[X, coords_i], kernels=kernels, data=data,\n",
    "                                                                  variance=uncert_i ** 2, mean=0.)\n",
    "                    output_coords.append(post_mean_i[:, None])\n",
    "                else:\n",
    "                    output_coords.append(Y_i[:, None])\n",
    "                star_post_mean_i, star_post_var_i = posterior_with_mask(Xstar=[Xstar, star_coords_i], kernels=kernels,\n",
    "                                                                        data=data,\n",
    "                                                                        variance=uncert_i ** 2, mean=0.)\n",
    "            star_output_coords.append(star_post_mean_i[:, None])\n",
    "\n",
    "            post_means_star.append(star_post_mean_i)\n",
    "            post_vars_star.append(star_post_var_i)\n",
    "\n",
    "        post_means_star = jnp.stack(post_means_star, axis=1)  # [H, M]\n",
    "        post_vars_star = jnp.stack(post_vars_star, axis=1)  # [H, M]\n",
    "\n",
    "        # Unnormalise\n",
    "        # post_means_star = self.normaliser.unnormalise_Y(post_means_star)\n",
    "        # post_vars_star = self.normaliser.unnormalise_Y_var(post_vars_star)\n",
    "        return post_means_star, post_vars_star\n",
    "\n",
    "    def sanity_check(self):\n",
    "        model: ParametrisedModel = self.model()\n",
    "        model.sanity_check(random.PRNGKey(0), S=100)\n",
    "\n",
    "    def fit(self) -> Tuple[NestedSamplerResults, hk.MutableParams]:\n",
    "        \"\"\"\n",
    "        Runs nested sampling.\n",
    "        \n",
    "        Returns:\n",
    "            The results of the nested sampling run.\n",
    "        \"\"\"\n",
    "        # Create the nested sampler class. In this case without any tuning.\n",
    "        results, params = EM(model=self.model()).train(num_steps=2)\n",
    "\n",
    "        summary(results)\n",
    "        plot_diagnostics(results)\n",
    "        plot_cornerplot(results)\n",
    "        return results, params\n",
    "\n",
    "    def posterior_predictive_f(self, results: NestedSamplerResults, Xstar: jnp.ndarray, map_estimate: bool = True) -> \\\n",
    "            Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Computes the posterior mean and variance of P(f_i | y_{i-1}, y_{i-2}, ..., y_1) for all i=1..M given the input data.\n",
    "        \n",
    "        Args:\n",
    "            results: The results of the nested sampling run.\n",
    "            Xstar: [N, D]\n",
    "            map_estimate: If True, use the MAP estimate, otherwise marginalise the posterior.\n",
    "\n",
    "        Returns:\n",
    "            The posterior mean, and variance of the data of shape [N, M] each\n",
    "        \"\"\"\n",
    "\n",
    "        def predict_f_fn(uncerts: List[jnp.ndarray], input_kernel_param: Dict[str, jnp.ndarray],\n",
    "                         output_kernel_params: List[Dict[str, Dict[str, jnp.ndarray]] | None]):\n",
    "            return gpar.predict_f(Xstar=Xstar, uncerts=uncerts, input_kernel_param=input_kernel_param,\n",
    "                                  output_kernel_params=output_kernel_params)\n",
    "\n",
    "        if map_estimate:\n",
    "            post_mean, post_var = evaluate_map_estimate_from_U(results=results, model=gpar.model, fun=predict_f_fn)\n",
    "        else:\n",
    "            post_mean, post_var = marginalise_static_from_U(\n",
    "                key=random.PRNGKey(42),\n",
    "                U_samples=results.U_samples,\n",
    "                model=gpar.model,\n",
    "                log_weights=results.log_dp_mean,\n",
    "                ESS=int(results.ESS), fun=predict_f_fn\n",
    "            )\n",
    "        return post_mean, post_var\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T17:52:00.347691586Z",
     "start_time": "2023-10-02T17:51:59.447490110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation: (0, 1, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m perm_indices \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39masarray(perm)\n\u001B[1;32m      8\u001B[0m gpar \u001B[38;5;241m=\u001B[39m GPAR(X\u001B[38;5;241m=\u001B[39mx_obs[:, \u001B[38;5;28;01mNone\u001B[39;00m], Y\u001B[38;5;241m=\u001B[39my_obs[:, perm_indices], Y_var\u001B[38;5;241m=\u001B[39my_obs_var[:, perm_indices], markov_ndims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      9\u001B[0m             replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mgpar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msanity_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m results \u001B[38;5;241m=\u001B[39m gpar\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m     13\u001B[0m post_mean, post_var \u001B[38;5;241m=\u001B[39m gpar\u001B[38;5;241m.\u001B[39mposterior_predictive_f(results\u001B[38;5;241m=\u001B[39mresults, Xstar\u001B[38;5;241m=\u001B[39mx[:, \u001B[38;5;28;01mNone\u001B[39;00m], map_estimate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[4], line 363\u001B[0m, in \u001B[0;36mGPAR.sanity_check\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msanity_check\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 363\u001B[0m     model: ParametrisedModel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\n\u001B[1;32m    364\u001B[0m     model\u001B[38;5;241m.\u001B[39msanity_check(random\u001B[38;5;241m.\u001B[39mPRNGKey(\u001B[38;5;241m0\u001B[39m), S\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/jax_py/lib/python3.10/functools.py:981\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[0;34m(self, instance, owner)\u001B[0m\n\u001B[1;32m    979\u001B[0m val \u001B[38;5;241m=\u001B[39m cache\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattrname, _NOT_FOUND)\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m _NOT_FOUND:\n\u001B[0;32m--> 981\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    982\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    983\u001B[0m         cache[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattrname] \u001B[38;5;241m=\u001B[39m val\n",
      "Cell \u001B[0;32mIn[4], line 87\u001B[0m, in \u001B[0;36mGPAR.model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;129m@cached_property\u001B[39m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodel\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ParametrisedModel:\n\u001B[0;32m---> 87\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParametrisedModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprior_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_prior_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_likelihood\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_likelihood\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/evidence_maximisation.py:86\u001B[0m, in \u001B[0;36mParametrisedModel.__init__\u001B[0;34m(self, base_model, params)\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model \u001B[38;5;241m=\u001B[39m base_model\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 86\u001B[0m     params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPRNGKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_params \u001B[38;5;241m=\u001B[39m params\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/evidence_maximisation.py:178\u001B[0m, in \u001B[0;36mParametrisedModel.init_params\u001B[0;34m(self, rng)\u001B[0m\n\u001B[1;32m    175\u001B[0m     log_prior_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mlog_prob_prior(U\u001B[38;5;241m=\u001B[39mU)\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m log_L \u001B[38;5;241m+\u001B[39m log_prior_prob\n\u001B[0;32m--> 178\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[43mhk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_joint_prob\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrng\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m params\n",
      "File \u001B[0;32m~/miniconda3/envs/jax_py/lib/python3.10/site-packages/haiku/_src/transform.py:170\u001B[0m, in \u001B[0;36mwithout_state.<locals>.init_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minit_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m hk\u001B[38;5;241m.\u001B[39mMutableParams:\n\u001B[0;32m--> 170\u001B[0m   params, state \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m state:\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m base\u001B[38;5;241m.\u001B[39mNonEmptyStateError(\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf your transformed function uses `hk.\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mget,set}_state` then use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    174\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`hk.transform_with_state`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/jax_py/lib/python3.10/site-packages/haiku/_src/transform.py:427\u001B[0m, in \u001B[0;36mtransform_with_state.<locals>.init_fn\u001B[0;34m(rng, *args, **kwargs)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m base\u001B[38;5;241m.\u001B[39mnew_context(rng\u001B[38;5;241m=\u001B[39mrng) \u001B[38;5;28;01mas\u001B[39;00m ctx:\n\u001B[1;32m    426\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 427\u001B[0m     \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    428\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m jax\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mUnexpectedTracerError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m jax\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mUnexpectedTracerError(unexpected_tracer_hint) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/evidence_maximisation.py:173\u001B[0m, in \u001B[0;36mParametrisedModel.init_params.<locals>.log_joint_prob\u001B[0;34m()\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_joint_prob\u001B[39m():\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;66;03m# A pure function that returns the log joint of model.\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     U \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_U\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPRNGKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m     log_L \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mforward(U\u001B[38;5;241m=\u001B[39mU)\n\u001B[1;32m    175\u001B[0m     log_prior_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mlog_prob_prior(U\u001B[38;5;241m=\u001B[39mU)\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/model.py:48\u001B[0m, in \u001B[0;36mModel.sample_U\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msample_U\u001B[39m(\u001B[38;5;28mself\u001B[39m, key: PRNGKey) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m FloatArray:\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m random\u001B[38;5;241m.\u001B[39muniform(key\u001B[38;5;241m=\u001B[39mkey, shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mU_ndims\u001B[49m,), dtype\u001B[38;5;241m=\u001B[39mfloat_type)\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/abc.py:153\u001B[0m, in \u001B[0;36mAbstractModel.U_ndims\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mU_ndims\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;124;03m    The prior dimensionality.\u001B[39;00m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mU_placeholder\u001B[49m\u001B[38;5;241m.\u001B[39msize\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/abc.py:139\u001B[0m, in \u001B[0;36mAbstractModel.U_placeholder\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mU_placeholder\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m UType:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;124;03m    A placeholder for U-space sample.\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparsed_prior\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/jax_py/lib/python3.10/functools.py:981\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[0;34m(self, instance, owner)\u001B[0m\n\u001B[1;32m    979\u001B[0m val \u001B[38;5;241m=\u001B[39m cache\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattrname, _NOT_FOUND)\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m _NOT_FOUND:\n\u001B[0;32m--> 981\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    982\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    983\u001B[0m         cache[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattrname] \u001B[38;5;241m=\u001B[39m val\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/abc.py:173\u001B[0m, in \u001B[0;36mAbstractModel.parsed_prior\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;129m@cached_property\u001B[39m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparsed_prior\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[UType, XType]:\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    The parsed prior.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m        U-space sample, X-space sample\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parsed_prior\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/model.py:42\u001B[0m, in \u001B[0;36mModel._parsed_prior\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_parsed_prior\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[UType, XType]:\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparse_prior\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprior_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprior_model\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/jaxns/jaxns/prior.py:209\u001B[0m, in \u001B[0;36mparse_prior\u001B[0;34m(prior_model)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;124;03mComputes placeholders of model.\u001B[39;00m\n\u001B[1;32m    201\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;124;03m    U placeholder, X placeholder\u001B[39;00m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    208\u001B[0m U_ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 209\u001B[0m gen \u001B[38;5;241m=\u001B[39m \u001B[43mprior_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m prior_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    211\u001B[0m X_placeholder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n",
      "\u001B[0;31mTypeError\u001B[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "# True logZ=-29.66 +- 0.11\n",
    "# False logZ=-30.45 +- 0.1\n",
    "for perm in permutations(list(range(y_obs.shape[1])), y_obs.shape[1]):\n",
    "    print(f\"Permutation: {perm}\")\n",
    "    perm_indices = jnp.asarray(perm)\n",
    "    gpar = GPAR(X=x_obs[:, None], Y=y_obs[:, perm_indices], Y_var=y_obs_var[:, perm_indices], markov_ndims=None,\n",
    "                replace=True)\n",
    "    gpar.sanity_check()\n",
    "    results = gpar.fit()\n",
    "\n",
    "    post_mean, post_var = gpar.posterior_predictive_f(results=results, Xstar=x[:, None], map_estimate=False)\n",
    "\n",
    "    # Plot posterior\n",
    "    for i in range(3):\n",
    "        plt.plot(x, f[:, i], label='f{}'.format(i))\n",
    "        plt.scatter(x_obs, y_obs[:, i], label='y{}'.format(i))\n",
    "        plt.plot(x, post_mean[:, i], label='post_mean{}'.format(i))\n",
    "        plt.plot(x, post_mean[:, i] + jnp.sqrt(post_var[:, i]), ls='dotted', c='black')\n",
    "        plt.plot(x, post_mean[:, i] - jnp.sqrt(post_var[:, i]), ls='dotted', c='black')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T17:52:00.392482509Z",
     "start_time": "2023-10-02T17:52:00.388497247Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def kernel_plot(data_dict):\n",
    "    \"\"\"\n",
    "    Generate a grid of kernel density estimates from a dictionary of data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_dict: Dict[str, np.ndarray] where each array is of shape (N, D_i)\n",
    "    \"\"\"\n",
    "    # Flatten the dictionary to get a list of all (label, data) pairs.\n",
    "    all_data = []\n",
    "    for key, array in data_dict.items():\n",
    "        if len(array.shape) == 1 or array.shape[1] == 1:  # 1D data\n",
    "            all_data.append((key, array))\n",
    "        else:  # 2D data\n",
    "            for idx in range(array.shape[1]):\n",
    "                label = f\"{key}[{idx}]\"\n",
    "                all_data.append((label, array[:, idx]))\n",
    "\n",
    "    n = len(all_data)\n",
    "\n",
    "    # Create a grid of subplots.\n",
    "    fig, axs = plt.subplots(n, n, figsize=(12, 12))\n",
    "\n",
    "    # Iterate over pairs of data to populate the grid.\n",
    "    for i, (label_i, data_i) in enumerate(all_data):\n",
    "        for j, (label_j, data_j) in enumerate(all_data):\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            if i == j:  # Diagonal\n",
    "                ax.hist(data_i, bins='auto', alpha=0.7, density=True)\n",
    "                ax.set_title(label_i)\n",
    "            else:  # Off-diagonal\n",
    "                differences = (data_i[:, None] - data_j).flatten()\n",
    "                kde = gaussian_kde(differences)\n",
    "                x_vals = np.linspace(differences.min(), differences.max(), 1000)\n",
    "                ax.plot(x_vals, kde(x_vals))\n",
    "\n",
    "                if i == n - 1:  # Only label the bottom-most subplots\n",
    "                    ax.set_xlabel(f\"Diff {label_j}\")\n",
    "                if j == 0:  # Only label the left-most subplots\n",
    "                    ax.set_ylabel(f\"Diff {label_i}\")\n",
    "\n",
    "            # Hide axis labels/ticks for other subplots for clarity.\n",
    "            if i != n - 1:\n",
    "                ax.set_xticks([])\n",
    "            if j != 0:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pair_plot(data_dict):\n",
    "    \"\"\"\n",
    "    Generate a pair plot from a dictionary of data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_dict: Dict[str, np.ndarray] where each array is of shape (N, D_i)\n",
    "    \"\"\"\n",
    "    # Flatten the dictionary to get a list of all (label, data) pairs.\n",
    "    all_data = []\n",
    "    for key, array in data_dict.items():\n",
    "        if len(array.shape) == 1 or array.shape[1] == 1:  # 1D data\n",
    "            all_data.append((key, array))\n",
    "        else:  # 2D data\n",
    "            for idx in range(array.shape[1]):\n",
    "                label = f\"{key}[{idx}]\"\n",
    "                all_data.append((label, array[:, idx]))\n",
    "\n",
    "    n = len(all_data)\n",
    "\n",
    "    # Create a grid of subplots.\n",
    "    fig, axs = plt.subplots(n, n, figsize=(12, 12))\n",
    "\n",
    "    # Iterate over pairs of data to populate the grid.\n",
    "    for i, (label_i, data_i) in enumerate(all_data):\n",
    "        for j, (label_j, data_j) in enumerate(all_data):\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            if i == j:  # Diagonal\n",
    "                ax.hist(data_i, bins='auto', alpha=0.7)\n",
    "                ax.set_title(label_i)\n",
    "            else:  # Off-diagonal\n",
    "                ax.scatter(data_j, data_i, alpha=0.5)\n",
    "                if i == n - 1:  # Only label the bottom-most subplots\n",
    "                    ax.set_xlabel(label_j)\n",
    "                if j == 0:  # Only label the left-most subplots\n",
    "                    ax.set_ylabel(label_i)\n",
    "\n",
    "            # Hide axis labels/ticks for other subplots for clarity.\n",
    "            if i != n - 1:\n",
    "                ax.set_xticks([])\n",
    "            if j != 0:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def covariance_plot(data_dict):\n",
    "    \"\"\"\n",
    "    Generate a grid of covariance plots from a dictionary of data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_dict: Dict[str, np.ndarray] where each array is of shape (N, D_i)\n",
    "    \"\"\"\n",
    "    # Flatten the dictionary to get a list of all (label, data) pairs.\n",
    "    all_data = []\n",
    "    for key, array in data_dict.items():\n",
    "        if len(array.shape) == 1 or array.shape[1] == 1:  # 1D data\n",
    "            all_data.append((key, array))\n",
    "        else:  # 2D data\n",
    "            for idx in range(array.shape[1]):\n",
    "                label = f\"{key}[{idx}]\"\n",
    "                all_data.append((label, array[:, idx]))\n",
    "\n",
    "    n = len(all_data)\n",
    "\n",
    "    # Create a grid of subplots.\n",
    "    fig, axs = plt.subplots(n, n, figsize=(12, 12))\n",
    "\n",
    "    # Iterate over pairs of data to populate the grid.\n",
    "    for i, (label_i, data_i) in enumerate(all_data):\n",
    "        for j, (label_j, data_j) in enumerate(all_data):\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            if i == j:  # Diagonal\n",
    "                ax.hist(data_i, bins='auto', alpha=0.7, density=True)\n",
    "                ax.set_title(label_i)\n",
    "            else:  # Off-diagonal\n",
    "                diff_i = data_i - data_i.mean()\n",
    "                diff_j = data_j - data_j.mean()\n",
    "                cov_matrix = np.outer(diff_i, diff_j) / len(data_i)\n",
    "\n",
    "                cax = ax.imshow(cov_matrix, aspect='auto', origin='lower',\n",
    "                                extent=[data_j.min(), data_j.max(), data_i.min(), data_i.max()])\n",
    "                plt.colorbar(cax, ax=ax)\n",
    "\n",
    "                if i == n - 1:  # Only label the bottom-most subplots\n",
    "                    ax.set_xlabel(label_j)\n",
    "                if j == 0:  # Only label the left-most subplots\n",
    "                    ax.set_ylabel(label_i)\n",
    "\n",
    "            # Hide axis labels/ticks for other subplots for clarity.\n",
    "            if i != n - 1:\n",
    "                ax.set_xticks([])\n",
    "            if j != 0:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def empirical_kernel_plot(data_dict):\n",
    "    \"\"\"\n",
    "    Generate a grid of empirical kernel visualizations from a dictionary of data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_dict: Dict[str, np.ndarray] where each array is of shape (N, D_i)\n",
    "    \"\"\"\n",
    "    # Flatten the dictionary to get a list of all (label, data) pairs.\n",
    "    all_data = []\n",
    "    for key, array in data_dict.items():\n",
    "        if len(array.shape) == 1 or array.shape[1] == 1:  # 1D data\n",
    "            all_data.append((key, array))\n",
    "        else:  # 2D data\n",
    "            for idx in range(array.shape[1]):\n",
    "                label = f\"{key}[{idx}]\"\n",
    "                all_data.append((label, array[:, idx]))\n",
    "\n",
    "    n = len(all_data)\n",
    "\n",
    "    # Create a grid of subplots.\n",
    "    fig, axs = plt.subplots(n, n, figsize=(12, 12))\n",
    "\n",
    "    # Iterate over pairs of data to populate the grid.\n",
    "    for i, (label_i, data_i) in enumerate(all_data):\n",
    "        for j, (label_j, data_j) in enumerate(all_data):\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            mean_i = np.mean(data_i)\n",
    "            mean_j = np.mean(data_j)\n",
    "\n",
    "            # Compute the empirical kernel for every pair (t, s).\n",
    "            kernel_matrix = (data_i[:, np.newaxis] - mean_i) * (data_j - mean_j)\n",
    "\n",
    "            im = ax.imshow(kernel_matrix, aspect='auto', cmap='RdBu_r')\n",
    "            if i == j:\n",
    "                ax.set_title(label_i)\n",
    "            else:\n",
    "                ax.set_title(f\"{label_i} vs {label_j}\")\n",
    "\n",
    "            if i == n - 1:  # Only label the bottom-most subplots\n",
    "                ax.set_xlabel('s')\n",
    "            if j == 0:  # Only label the left-most subplots\n",
    "                ax.set_ylabel('t')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "data = {\n",
    "    \"X\": x,\n",
    "    \"Y\": y\n",
    "}\n",
    "\n",
    "pair_plot(data)\n",
    "empirical_kernel_plot(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-02T17:52:00.388571412Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
